{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modeling\n",
    "\n",
    "_By [Michael Rosenberg](mailto:rosenberg.michael.m@gmail.com)._\n",
    "\n",
    "_**Description**: Contains my initial modeling techniques based on the intuition developed from my [EDA](eda.ipynb)._\n",
    "\n",
    "_Last Updated: 9/5/2017 7:01 PM._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "#helpers\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "sigLev = 3\n",
    "percentLev = 100\n",
    "alphaLev = .2\n",
    "numBins = 30\n",
    "pd.set_option(\"display.precision\",sigLev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in data\n",
    "trainFrame = pd.read_csv(\"../data/raw/train.csv\")\n",
    "testFrame = pd.read_csv(\"../data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some helpers\n",
    "def exportPredictions(testFrame,predictorVars,model,predictionName,\n",
    "                      predictingLog = False):\n",
    "    #helper for exporting our predictions\n",
    "    predictionMat = testFrame[predictorVars]\n",
    "    testFrame[\"trip_duration\"] = model.predict(predictionMat)\n",
    "    if (predictingLog): #need to exponentiate\n",
    "        testFrame[\"trip_duration\"] = np.exp(testFrame[\"trip_duration\"])\n",
    "    #then export\n",
    "    exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "    if (\".csv\" not in predictionName):\n",
    "        predictionName += \".csv\" #just to keep consistency\n",
    "    exportFrame.to_csv(predictionName,index = False)\n",
    "    \n",
    "def exportModel(model,modelName):\n",
    "    #helper for exporting our model\n",
    "    pkl.dump(model,open(modelName,\"wb\"))\n",
    "    \n",
    "def rmsle(predictions,actuals):\n",
    "    #helper for calculating RMSLE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day-Intensive Model\n",
    "\n",
    "While our EDA would suggest otherwise, I would argue that it makes sense for trip duration to be informed by the time of day of the trip. In particular, on a certain day of the week and at a certain hour, we should expect a certain level of traffic within the city. Let's start with a main effects model, and then fit a set of interaction effects. For our initial model types, we will just consider linear models. Based on our initial analysis, we will predict $\\log(Trip Duration)$ and then exponentiate our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get day of week and hour\n",
    "trainFrame[\"pickup_datetime\"] = pd.to_datetime(trainFrame[\"pickup_datetime\"])\n",
    "trainFrame[\"pickup_dow\"] = trainFrame[\"pickup_datetime\"].dt.dayofweek\n",
    "trainFrame[\"pickup_hour\"] = trainFrame[\"pickup_datetime\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFrame[\"logTripDuration\"] = np.log(trainFrame[\"trip_duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get main effects\n",
    "#day of week\n",
    "dowEncoder = pp.OneHotEncoder()\n",
    "trainDOWMat = np.array(trainFrame[\"pickup_dow\"]).reshape(-1,1)\n",
    "trainDOWMat = dowEncoder.fit_transform(trainDOWMat)\n",
    "#hour\n",
    "hourEncoder = pp.OneHotEncoder()\n",
    "trainHourMat = np.array(trainFrame[\"pickup_hour\"]).reshape(-1,1)\n",
    "trainHourMat = hourEncoder.fit_transform(trainHourMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then get our feature matrix\n",
    "trainFeatureMat = sp.sparse.hstack((trainDOWMat,trainHourMat))\n",
    "#then fit linear regression\n",
    "initLinReg = lm.LinearRegression()\n",
    "initLinReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then get the same information for test frame\n",
    "testFrame[\"pickup_datetime\"] = pd.to_datetime(testFrame[\"pickup_datetime\"])\n",
    "testFrame[\"pickup_dow\"] = testFrame[\"pickup_datetime\"].dt.dayofweek\n",
    "testFrame[\"pickup_hour\"] = testFrame[\"pickup_datetime\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get main effects\n",
    "#day of week\n",
    "dowEncoder = pp.OneHotEncoder()\n",
    "testDOWMat = np.array(testFrame[\"pickup_dow\"]).reshape(-1,1)\n",
    "testDOWMat = dowEncoder.fit_transform(testDOWMat)\n",
    "#hour\n",
    "hourEncoder = pp.OneHotEncoder()\n",
    "testHourMat = np.array(testFrame[\"pickup_hour\"]).reshape(-1,1)\n",
    "testHourMat = hourEncoder.fit_transform(testHourMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFeatureMat = sp.sparse.hstack((testDOWMat,testHourMat))\n",
    "testFrame[\"logPredictions\"] = initLinReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then export information\n",
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\"../data/processed/dowHourPredictions.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets us in at an RMSLE of around $.79$. Not bad for a first try! Let's see if we can do any better once we throw our DOW-Hour interactions into the pot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(trainFrame[\"pickup_dow\"].unique())):\n",
    "    #get particular day's dummy encoding\n",
    "    givenDOWDummy = sp.sparse.diags(np.squeeze(trainDOWMat[:,i].toarray()))\n",
    "    givenDOWHourInteractions = givenDOWDummy * trainHourMat\n",
    "    #then add to our feature matrix\n",
    "    trainFeatureMat = sp.sparse.hstack((trainFeatureMat,\n",
    "                                        givenDOWHourInteractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then fit\n",
    "intLinReg = lm.LinearRegression()\n",
    "intLinReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do the same for test\n",
    "for i in xrange(len(testFrame[\"pickup_dow\"].unique())):\n",
    "    #get particular day's dummy encoding\n",
    "    givenDOWDummy = sp.sparse.diags(np.squeeze(testDOWMat[:,i].toarray()))\n",
    "    givenDOWHourInteractions = givenDOWDummy * testHourMat\n",
    "    #then add to our feature matrix\n",
    "    testFeatureMat = sp.sparse.hstack((testFeatureMat,\n",
    "                                        givenDOWHourInteractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = intLinReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then export information\n",
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\"../data/processed/dowHourInteractionPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This barely improves our performance. Let's see if we do any better when we predict outside the log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonLogLinReg = lm.LinearRegression()\n",
    "nonLogLinReg.fit(trainFeatureMat,trainFrame[\"trip_duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"trip_duration\"] = nonLogLinReg.predict(testFeatureMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then export information\n",
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\"../data/processed/dowHourInteractionPredictions_nonLog.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I had expected, we do much better when we predict in log space and then exponentiate back into the non-logged space. Just goes to show!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Number of Passengers Encoding\n",
    "\n",
    "As discussed before, we recognize that when we consider only those observations that have $0$ passengers, we get a much lower distribution of $\\log(TripDuration)$ than when we have more than $0$ passengers. Let's throw it in there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFrame[\"moreThan0Passengers\"] = 0\n",
    "trainFrame.loc[trainFrame[\"passenger_count\"] > 0,\n",
    "               \"moreThan0Passengers\"] = 1\n",
    "testFrame[\"moreThan0Passengers\"] = 0\n",
    "testFrame.loc[testFrame[\"passenger_count\"] > 0,\n",
    "               \"moreThan0Passengers\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainPassengerFeatureMat = sp.sparse.csc_matrix(\n",
    "                                            trainFrame[\"moreThan0Passengers\"]).T\n",
    "testPassengerFeatureMat = sp.sparse.csc_matrix(\n",
    "                                            testFrame[\"moreThan0Passengers\"]).T\n",
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,trainPassengerFeatureMat))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,testPassengerFeatureMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linRegWithPassenger = lm.LinearRegression()\n",
    "linRegWithPassenger.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])\n",
    "testFrame[\"logPredictions\"] = linRegWithPassenger.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\"../data/processed/dhInteractionWithPassPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight improvement, but only by so much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality\n",
    "\n",
    "Let's introduce a notion of seasonality into our problem by inserting month into our feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFrame[\"pickup_month\"] = trainFrame[\"pickup_datetime\"].dt.month\n",
    "testFrame[\"pickup_month\"] = testFrame[\"pickup_datetime\"].dt.month\n",
    "#get encoding\n",
    "monthEncoder = pp.OneHotEncoder()\n",
    "trainMonthMat = monthEncoder.fit_transform(\n",
    "                            np.array(trainFrame[\"pickup_month\"]).reshape(-1,1))\n",
    "testMonthMat = monthEncoder.transform(\n",
    "                            np.array(testFrame[\"pickup_month\"]).reshape(-1,1))\n",
    "#then append\n",
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,trainMonthMat))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,testMonthMat))\n",
    "#then get a linear regression\n",
    "newReg = lm.LinearRegression()\n",
    "newReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])\n",
    "#then predict\n",
    "testFrame[\"logPredictions\"] = newReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/dhInteractionWithPassAndSeasonPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That shot us up a place in the leaderboard! Good job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Location\n",
    "\n",
    "One thing I am interested in is creating a measure of location. We can do this by creating tile encodings of location on our map of longitude and latitude of pickup points. Let's try to create this tile encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateTileEncoding(featureFrame,locType,minLocLat,\n",
    "                         maxLocLat,minLocLong,maxLocLong,step):\n",
    "    #helper for generating our tile encoding for a given location type\n",
    "    locLat = locType + \"_latitude\"\n",
    "    locLong = locType + \"_longitude\"\n",
    "    #get min and max for both\n",
    "    #need trainframe so as to standardize the search on both parameter sets\n",
    "    #then form latitude and longitude ranges\n",
    "    latRange = np.arange(minLocLat,maxLocLat,step)\n",
    "    longRange = np.arange(minLocLong,maxLocLong,step)\n",
    "    #then get our matrix\n",
    "    tileEncodingMat =  np.zeros((featureFrame.shape[0],len(latRange)*\n",
    "                                                      len(longRange)))\n",
    "    #then step through our ranges\n",
    "    for i in xrange(len(latRange)):\n",
    "        for j in xrange(len(longRange)):\n",
    "            #get our box\n",
    "            lat, lon = latRange[i], longRange[j]\n",
    "            x0, y0, x1, y1 = lon, lat, lon + step, lat + step\n",
    "            #form our tile encoding\n",
    "            condition = ((x0 <= featureFrame[locLong]) &\n",
    "                         (featureFrame[locLong] <= x1) &\n",
    "                         (y0 <= featureFrame[locLat]) &\n",
    "                         (featureFrame[locLat] <= y1))\n",
    "            tileEncoding = list(condition.astype(\"int\"))\n",
    "            tileEncodingMat[:,(i * len(longRange) + j)] = tileEncoding\n",
    "    #then filter out 0 variance observationa\n",
    "    #tileEncodingMat = tileEncodingMat[:,(tileEncodingMat.sum(axis = 0) > 0)]\n",
    "    return tileEncodingMat\n",
    "\n",
    "trainPickupEncodingMat = generateTileEncoding(trainFrame,\"pickup\",\n",
    "                                             40.2,41.8,-75,-72.5,.1)\n",
    "trainDropoffEncodingMat = generateTileEncoding(trainFrame,\"dropoff\",\n",
    "                                             40.2,41.8,-75,-72.5,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,\n",
    "                                sp.sparse.csr_matrix(trainPickupEncodingMat)))\n",
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,\n",
    "                                sp.sparse.csr_matrix(trainDropoffEncodingMat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tileReg = lm.LinearRegression()\n",
    "tileReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testPickupEncodingMat = generateTileEncoding(testFrame,\"pickup\",\n",
    "                                             40.2,41.8,-75,-72.5,.1)\n",
    "testDropoffEncodingMat = generateTileEncoding(testFrame,\"dropoff\",\n",
    "                                             40.2,41.8,-75,-72.5,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,\n",
    "                                sp.sparse.csr_matrix(testPickupEncodingMat)))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,\n",
    "                                sp.sparse.csr_matrix(testDropoffEncodingMat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = tileReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/tileEncodingSectoredPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like that helped out a bit! Let's see what happens when we introduce a notion of distance into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "trainFrame[\"distance\"] = [haversine((x[1][\"pickup_longitude\"],\n",
    "                                       x[1][\"pickup_latitude\"]),\n",
    "                                      (x[1][\"dropoff_longitude\"],\n",
    "                                       x[1][\"dropoff_latitude\"])) for x in\n",
    "                          trainFrame.iterrows()]\n",
    "\n",
    "testFrame[\"distance\"] = [haversine((x[1][\"pickup_longitude\"],\n",
    "                                       x[1][\"pickup_latitude\"]),\n",
    "                                      (x[1][\"dropoff_longitude\"],\n",
    "                                       x[1][\"dropoff_latitude\"])) for x in\n",
    "                        testFrame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDistanceMat = sp.sparse.csc_matrix(np.array(trainFrame[\"distance\"])).T\n",
    "testDistanceMat = sp.sparse.csc_matrix(np.array(testFrame[\"distance\"])).T\n",
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,trainDistanceMat))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,testDistanceMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then fit\n",
    "distanceMod = lm.LinearRegression()\n",
    "distanceMod.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = distanceMod.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/tileEncodingWithDistancePredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding that got us way ahead! Let's see if the interaction between distance time of day has any impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDistanceDiag = sp.sparse.diags(np.array(trainFrame[\"distance\"]))\n",
    "testDistanceDiag = sp.sparse.diags(np.array(testFrame[\"distance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDistHourInteractions = trainDistanceDiag * trainHourMat\n",
    "testDistHourInteractions = testDistanceDiag * testHourMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,trainDistHourInteractions))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,testDistHourInteractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distanceIntMod = lm.LinearRegression()\n",
    "distanceIntMod.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = distanceIntMod.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/tileEncodingWithDistanceIntPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Now that the model has gotten quite big:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1458644x1031 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 13115873 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatureMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should consider some form of regularization. I think starting with an $L_2$ regularizer is reasonable given we have around $1031$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeReg = lm.Ridge()\n",
    "ridgeReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = ridgeReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/ridgeRegressionPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform slightly worse in the context of the ridge regression. We can do better! Let's try some other variable transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Distance Metrics\n",
    "\n",
    "Having observed some other [Kaggle Kernels](https://www.kaggle.com/priyanka13/nyc-using-xgboost-0-41), I thought to include some other relevant forms of distance. In particular, I want to include [Vincenty Distance](https://en.wikipedia.org/wiki/Vincenty's_formulae) and [Great Circle Distance](https://en.wikipedia.org/wiki/Great-circle_distance) within our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy.distance import vincenty, great_circle\n",
    "trainFrame[\"vincentyDistance\"] = [vincenty((x[1]['pickup_latitude'],\n",
    "                                           x[1]['pickup_longitude']),\n",
    "            (x[1]['dropoff_latitude'], x[1]['dropoff_longitude'])).miles for\n",
    "                    x in trainFrame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vincenty distance\n",
    "testFrame[\"vincentyDistance\"] = [vincenty((x[1]['pickup_latitude'],\n",
    "                                           x[1]['pickup_longitude']),\n",
    "            (x[1]['dropoff_latitude'], x[1]['dropoff_longitude'])).miles for\n",
    "                    x in testFrame.iterrows()]\n",
    "#great circle distance\n",
    "trainFrame[\"gcDistance\"] = [great_circle((x[1]['pickup_latitude'],\n",
    "                                           x[1]['pickup_longitude']),\n",
    "            (x[1]['dropoff_latitude'], x[1]['dropoff_longitude'])).miles for\n",
    "                    x in trainFrame.iterrows()]\n",
    "testFrame[\"gcDistance\"] = [great_circle((x[1]['pickup_latitude'],\n",
    "                                           x[1]['pickup_longitude']),\n",
    "            (x[1]['dropoff_latitude'], x[1]['dropoff_longitude'])).miles for\n",
    "                    x in testFrame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainNewDistanceMat = np.array(trainFrame[[\"vincentyDistance\",\"gcDistance\"]])\n",
    "trainNewDistanceMat = sp.sparse.csc_matrix(trainNewDistanceMat)\n",
    "testNewDistanceMat = np.array(testFrame[[\"vincentyDistance\",\"gcDistance\"]])\n",
    "testNewDistanceMat = sp.sparse.csc_matrix(testNewDistanceMat)\n",
    "#then add them in\n",
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,trainNewDistanceMat))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,testNewDistanceMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDistanceMod = lm.LinearRegression()\n",
    "newDistanceMod.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = newDistanceMod.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/newDistancePredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well these perform when we add hour interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Model Types\n",
    "\n",
    "Let's see if a decision tree might work better in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "treeReg = tree.DecisionTreeRegressor()\n",
    "treeReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = treeReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/treeRegPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That fits slowly. Let's try a neural net! Because of course we have to use fucking neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnReg = MLPRegressor()\n",
    "nnReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = nnReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/neuralNetRegPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That put us in the top $63\\%$! Let's check out support vector regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svReg = svm.SVR()\n",
    "svReg.fit(trainFeatureMat,trainFrame[\"logTripDuration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = svReg.predict(testFeatureMat)\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/supportVectorRegPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNN = Sequential()\n",
    "newNN.add(Dense(100,input_dim = trainFeatureMat.shape[1],\n",
    "                activation = \"relu\"))\n",
    "newNN.add(Dense(50,activation = \"sigmoid\"))\n",
    "newNN.add(Dense(1,activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newNN.compile(loss = \"mean_squared_error\",optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1458644/1458644 [==============================] - 251s - loss: 0.2032 - acc: 0.0000e+00   \n",
      "Epoch 2/2\n",
      "1458644/1458644 [==============================] - 267s - loss: 0.2023 - acc: 0.0000e+00   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120a31f10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newNN.fit(trainFeatureMat.toarray(),np.array(trainFrame[\"logTripDuration\"]),\n",
    "          epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = newNN.predict(testFeatureMat.toarray())\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/kerasRegPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did really well! Let's try another neural net with an additional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newNN = Sequential()\n",
    "newNN.add(Dense(100,input_dim = trainFeatureMat.shape[1],\n",
    "                activation = \"relu\"))\n",
    "newNN.add(Dense(50,activation = \"sigmoid\"))\n",
    "newNN.add(Dense(25,activation = \"elu\"))\n",
    "newNN.add(Dense(1,activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNN.compile(loss = \"mean_squared_error\",optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1458644/1458644 [==============================] - 162s - loss: 0.2272 - acc: 0.0000e+00   \n",
      "Epoch 2/3\n",
      "1458644/1458644 [==============================] - 202s - loss: 0.2066 - acc: 0.0000e+00   \n",
      "Epoch 3/3\n",
      "1458644/1458644 [==============================] - 228s - loss: 0.2050 - acc: 0.0000e+00   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12111d1d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newNN.fit(trainFeatureMat.toarray(),np.array(trainFrame[\"logTripDuration\"]),\n",
    "          epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFrame[\"logPredictions\"] = newNN.predict(testFeatureMat.toarray())\n",
    "testFrame[\"trip_duration\"] = np.exp(testFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = testFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/kerasSecondRegPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce OSRM Data\n",
    "\n",
    "Let's see how well we can perform when we introduce OSRM data from [here](https://www.kaggle.com/oscarleo/new-york-city-taxi-with-osrm). This will allow us to include information on the fastest route, including its travel time, number of steps, and total distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFastestRouteFrame_p1 = pd.read_csv(\n",
    "                    \"../data/preprocessed/osrm/fastest_routes_train_part_1.csv\")\n",
    "trainFastestRouteFrame_p2 = pd.read_csv(\n",
    "                    \"../data/preprocessed/osrm/fastest_routes_train_part_2.csv\")\n",
    "testFastestRouteFrame = pd.read_csv(\n",
    "                    \"../data/preprocessed/osrm/fastest_routes_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFastestRouteFrame = pd.concat([trainFastestRouteFrame_p1,\n",
    "                                    trainFastestRouteFrame_p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFrame = trainFrame.merge(trainFastestRouteFrame,on = \"id\",how = \"left\")\n",
    "testFrame = testFrame.merge(testFastestRouteFrame,on = \"id\",how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure there are no `NaN` features when adding these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainCondition = ((trainFrame[\"total_distance\"].notnull()) &\n",
    "                  (trainFrame[\"total_travel_time\"].notnull()) &\n",
    "                  (trainFrame[\"number_of_steps\"].notnull()))\n",
    "testConditon = ((testFrame[\"total_distance\"].notnull()) &\n",
    "                  (testFrame[\"total_travel_time\"].notnull()) &\n",
    "                  (testFrame[\"number_of_steps\"].notnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filteredTrainFrame = trainFrame[trainCondition]\n",
    "filteredTestFrame = testFrame[testConditon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get remainder indices\n",
    "trainRemainderIndices = list(filteredTrainFrame.index)\n",
    "testRemainderIndices = list(filteredTestFrame.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#then filter variables\n",
    "trainFeatureMat = trainFeatureMat.tocsc()[trainRemainderIndices,:]\n",
    "testFeatureMat = testFeatureMat.tocsc()[testRemainderIndices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then pull information into sparse matrices\n",
    "osrmVars = [\"total_distance\",\"total_travel_time\",\"number_of_steps\"]\n",
    "trainOSRMMat = sp.sparse.csc_matrix(filteredTrainFrame[osrmVars])\n",
    "testOSRMMat = sp.sparse.csc_matrix(filteredTestFrame[osrmVars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#then stack them\n",
    "trainFeatureMat = sp.sparse.hstack((trainFeatureMat,trainOSRMMat))\n",
    "testFeatureMat = sp.sparse.hstack((testFeatureMat,testOSRMMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#then build a new neural net\n",
    "newNN = Sequential()\n",
    "newNN.add(Dense(100,input_dim = trainFeatureMat.shape[1],\n",
    "                activation = \"relu\"))\n",
    "newNN.add(Dense(50,activation = \"relu\"))\n",
    "newNN.add(Dense(25,activation = \"elu\"))\n",
    "newNN.add(Dense(1,activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNN.compile(loss = \"mean_squared_error\",optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1458643/1458643 [==============================] - 242s - loss: 2.0310 - acc: 0.0000e+00   \n",
      "Epoch 2/3\n",
      "1458643/1458643 [==============================] - 247s - loss: 0.2298 - acc: 0.0000e+00   \n",
      "Epoch 3/3\n",
      "1458643/1458643 [==============================] - 273s - loss: 0.2124 - acc: 0.0000e+00   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4c24b5810>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newNN.fit(trainFeatureMat.toarray(),\n",
    "          np.array(filteredTrainFrame[\"logTripDuration\"]),\n",
    "          epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filteredTestFrame[\"logPredictions\"] = newNN.predict(testFeatureMat.toarray())\n",
    "filteredTestFrame[\"trip_duration\"] = np.exp(\n",
    "                                filteredTestFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = filteredTestFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/osrmReg2Predictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't do any better. Let's see if we can do any better by changing up some of our activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then build a new neural net\n",
    "newNN = Sequential()\n",
    "newNN.add(Dense(100,input_dim = trainFeatureMat.shape[1],\n",
    "                activation = \"relu\"))\n",
    "newNN.add(Dense(50,activation = \"sigmoid\"))\n",
    "newNN.add(Dense(25,activation = \"elu\"))\n",
    "newNN.add(Dense(10,activation = \"relu\"))\n",
    "newNN.add(Dense(1,activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNN.compile(loss = \"mean_squared_error\",optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newNN.fit(trainFeatureMat.toarray(),\n",
    "          np.array(filteredTrainFrame[\"logTripDuration\"]),\n",
    "          epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filteredTestFrame[\"logPredictions\"] = newNN.predict(testFeatureMat.toarray())\n",
    "filteredTestFrame[\"trip_duration\"] = np.exp(\n",
    "                                filteredTestFrame[\"logPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportFrame = filteredTestFrame[[\"id\",\"trip_duration\"]]\n",
    "exportFrame.to_csv(\n",
    "            \"../data/processed/osrmMoreLayerRegPredictions.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
